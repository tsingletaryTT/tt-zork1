# Pinned Memory Discovery - Direct Host Write from RISC-V!

**Date:** 2026-01-27
**Discovery:** TT-Metal supports **direct RISC-V â†’ host memory writes** via PinnedMemory API!

## The Breakthrough

User overheard in a meeting: *"run something on the X280 that can write to host memory"*

This led to discovering **`tt::tt_metal::experimental::PinnedMemory`** - a game-changing API!

## What is PinnedMemory?

**From TT-Metal documentation:**
> PinnedMemory manages system memory buffers across multiple devices. This class provides a convenient wrapper around UMD SysmemBuffers, managing one buffer per device in a mesh or set of devices. It handles allocation, mapping, and access to pinned system memory that **can be accessed by the devices**.

**Key capabilities:**
- Host allocates memory
- Memory is **mapped to NoC** (device can access via NoC addresses)
- Device can **read AND WRITE** to this memory
- **No DRAM buffers needed!**

## Architecture Comparison

### OLD (Current - BROKEN):
```
Host â†’ Create device â†’ Allocate DRAM buffers â†’ Execute kernel â†’ Close device
                                                                      â†“
                                                            [Second run HANGS]
```

### NEW (PinnedMemory - BREAKTHROUGH):
```
Host â†’ Create device â†’ Allocate PinnedMemory (ONCE)
         â†“
         Device stays open FOREVER
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Continuous Loop:           â”‚
    â”‚  1. RISC-V executes Z-code â”‚
    â”‚  2. Writes output to       â”‚
    â”‚     pinned host memory     â”‚ â† Direct NoC write!
    â”‚  3. Host reads output      â”‚ â† Just memcpy from host ptr!
    â”‚  4. Host sends new input   â”‚
    â”‚  5. Repeat                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Close device ONCE (at program exit only)
```

## API Overview

### Host Side (C++):

```cpp
#include <tt-metalium/experimental/pinned_memory.hpp>

// 1. Create pinned memory
auto host_buffer = HostBuffer::create(OUTPUT_SIZE);
auto pinned_memory = experimental::PinnedMemory::Create(
    *mesh_device,
    coordinate_range_set,
    *host_buffer,
    /*map_to_noc=*/true  // â† KEY! Maps to NoC for device access
);

// 2. Get NoC address for kernel
auto noc_addr = pinned_memory->get_noc_addr(device_id);
if (noc_addr.has_value()) {
    uint64_t noc_address = noc_addr->addr;
    uint32_t pcie_xy_enc = noc_addr->pcie_xy_enc;
    // Pass these to kernel...
}

// 3. Host reads output (any time!)
void* host_ptr = pinned_memory->lock();  // Wait for device writes
char* output = static_cast<char*>(host_ptr);
std::string game_text(output);  // Direct memory access!
pinned_memory->unlock();
```

### Kernel Side (RISC-V):

```cpp
// In kernel (kernels/zork_interpreter.cpp):

// Receive NoC address as compile-time define or runtime arg
constexpr uint64_t OUTPUT_NOC_ADDR = /* from host */;
constexpr uint32_t PCIE_XY_ENC = /* from host */;

// Execute Z-machine
char output[1024];
interpret(100, output);  // Fill output buffer

// Write DIRECTLY to host memory via NoC!
noc_async_write(
    (uint32_t)output,        // Source: L1 address
    OUTPUT_NOC_ADDR,         // Destination: Host memory!
    strlen(output),          // Size
    0,                       // NOC 0
    NOC_UNICAST_WRITE_VC     // VC
);
noc_async_write_barrier();  // Wait for completion
```

## Key Benefits

### 1. **Device Stays Open**
- Initialize ONCE at program start
- No more close/reopen cycle
- **Eliminates the device init hang bug!**

### 2. **Zero-Copy Output**
- RISC-V writes directly to host RAM
- No DRAM buffer intermediate step
- No EnqueueReadBuffer overhead
- **Faster and simpler!**

### 3. **Streaming Output**
- Host can poll memory region
- See game text as it's generated
- Real-time output display
- **Better user experience!**

### 4. **Persistent Execution**
- Kernel can run in infinite loop
- Wait for input from host
- Execute when signaled
- **True persistent runtime!**

## NoC Write Capabilities

From `dataflow_api.h` documentation:

> The destination node can be either:
> - A DRAM bank
> - Tensix core + L1 memory address
> - **A PCIe controller** â† THIS IS THE KEY!

PinnedMemory provides the NoC address that points through the PCIe controller to host memory!

## Implementation Plan

### Phase 1: Proof of Concept âœ… (This Document)
- [x] Discover PinnedMemory API
- [x] Understand NoC write to host
- [x] Document architecture

### Phase 2: Simple Test
1. Create pinned memory buffer (16KB)
2. Create kernel that writes "Hello from RISC-V!" to pinned memory
3. Host reads from pinned memory pointer
4. **Verify direct host write works**

### Phase 3: Z-Machine Integration
1. Allocate pinned memory for output (16KB)
2. Pass NoC address to Z-machine kernel
3. Kernel writes game text to pinned host memory
4. Host polls/reads game text
5. **Eliminate DRAM output buffer completely**

### Phase 4: Persistent Execution Loop
1. Add pinned input buffer (for commands)
2. Kernel runs in loop:
   - Wait for input flag
   - Execute Z-machine instructions
   - Write output to pinned memory
   - Set output ready flag
3. Host:
   - Write command to input buffer
   - Set input flag
   - Wait for output flag
   - Read output
   - Repeat
4. **Device never closes!**

## Code References

### TT-Metal Files:
- **API Header:** `tt_metal/api/tt-metalium/experimental/pinned_memory.hpp`
- **Test Example:** `tests/tt_metal/distributed/test_mesh_buffer.cpp`
  - See `EnqueueReadShardsWithPinnedMemoryFullRange` test
- **NoC API:** `tt_metal/hw/inc/api/dataflow/dataflow_api.h`
  - Functions: `noc_async_write`, `noc_async_write_barrier`

### Functions to Use:
```cpp
// Host side:
experimental::PinnedMemory::Create()
pinned_memory->get_noc_addr(device_id)
pinned_memory->lock() / unlock()
pinned_memory->get_host_ptr()

// Kernel side:
noc_async_write(src_l1_addr, dst_noc_addr, size)
noc_async_write_barrier()
```

## Platform Requirements

**Check support:**
```cpp
auto params = experimental::GetMemoryPinningParameters(*mesh_device);
if (params.can_map_to_noc) {
    // PinnedMemory with NoC mapping is supported!
} else {
    // Fall back to DRAM buffers
}
```

## Performance Expected

### Current (with device reset):
- Per batch: 2-3s device init + 0.5s execution = **2.5-3.5s**
- 10 batches: **25-35 seconds**

### With PinnedMemory:
- Device init: 2-3s (ONCE at startup)
- Per batch: 0.5s execution + 0.001s NoC write = **~0.5s**
- 10 batches: 3s + (10 Ã— 0.5s) = **8 seconds**
- **3-4x faster!**

### With Persistent Loop (future):
- Device init: 2-3s (ONCE)
- Per batch: 0.5s execution + 0.001s write + polling overhead = **~0.6s**
- 10 batches: 3s + (10 Ã— 0.6s) = **9 seconds**
- No Python subprocess overhead!

## X280 Mystery

**Question:** What does "X280" refer to?

**Hypotheses:**
1. **Core coordinate** - CoreCoord(2, 8, 0)?
2. **PCIe coordinate** - Encoded PCIe XY location?
3. **Special core type** - Specific RISC-V core with host write capability?
4. **Internal codename** - TT-Metal development term?

**Investigation needed:**
- Search TT-Metal for "X280" or "x280"
- Check if all RISC-V cores can write to host, or only specific ones
- Examine pcie_xy_enc encoding

## Next Steps

1. âœ… Document PinnedMemory discovery
2. Create simple test: kernel writes "Hello" to host memory
3. Test on Blackhole hardware
4. Integrate with Z-machine interpreter
5. Eliminate DRAM output buffer
6. Build persistent execution loop
7. **Achieve true continuous Zork gameplay!**

## Bottom Line

ğŸ‰ **This is the breakthrough we needed!**

PinnedMemory solves:
- âœ… Device close/reopen hang (device stays open)
- âœ… DRAM buffer overhead (direct host access)
- âœ… Batching complexity (continuous execution)
- âœ… Performance (3-4x faster)

**We can finally achieve the vision:** Zork running continuously on RISC-V cores with direct host memory I/O!
